{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM78uEBcJMhlKfKZTtTEyHH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/proshanta000/langgraph_l/blob/main/langgraph_chatbot_with_Tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Uninstall everything to clear the conflicts\n",
        "#!pip uninstall -y langchain langgraph langchain-community langchain-core langchain-groq pydantic"
      ],
      "metadata": {
        "id": "vbXSmw9lz591",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f28e9c-8071-44a5-bd90-d93794179f2d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: langchain 0.3.27\n",
            "Uninstalling langchain-0.3.27:\n",
            "  Successfully uninstalled langchain-0.3.27\n",
            "\u001b[33mWARNING: Skipping langgraph as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping langchain-community as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: langchain-core 0.3.79\n",
            "Uninstalling langchain-core-0.3.79:\n",
            "  Successfully uninstalled langchain-core-0.3.79\n",
            "\u001b[33mWARNING: Skipping langchain-groq as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: pydantic 2.11.10\n",
            "Uninstalling pydantic-2.11.10:\n",
            "  Successfully uninstalled pydantic-2.11.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe9tz0BWEbw2",
        "outputId": "bfb84e0b-b291-4911-e266-1865b6009438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.12/dist-packages (0.4.42)\n",
            "Collecting langchain\n",
            "  Downloading langchain-1.0.7-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-1.0.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting arxiv\n",
            "  Downloading arxiv-2.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting langchain-core>=0.1 (from langgraph)\n",
            "  Downloading langchain_core-1.0.5-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-1.0.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting pydantic>=2.7.4 (from langgraph)\n",
            "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith) (3.11.4)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langsmith) (25.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.25.0)\n",
            "Collecting groq<1.0.0,>=0.30.0 (from langchain_groq)\n",
            "  Downloading groq-0.34.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain_community)\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.44)\n",
            "Collecting requests>=2.0.0 (from langsmith)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Collecting feedparser~=6.0.10 (from arxiv)\n",
            "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (4.13.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (4.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain_community)\n",
            "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Collecting pydantic-core==2.41.5 (from pydantic>=2.7.4->langgraph)\n",
            "  Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (2.8)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langgraph-1.0.3-py3-none-any.whl (156 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-1.0.7-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.7/93.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-1.0.1-py3-none-any.whl (17 kB)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading arxiv-2.3.1-py3-none-any.whl (11 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-0.34.1-py3-none-any.whl (136 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.0/136.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.0.5-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.5/471.5 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.4-py3-none-any.whl (34 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.4/463.4 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.3/208.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: wikipedia, sgmllib3k\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=8f3f865cff2e04fedeab567a5ddb2f20417275c0d027dd46b8ce759094e8134f\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/47/7c/a9688349aa74d228ce0a9023229c6c0ac52ca2a40fe87679b8\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=55a49009f60b1272031a5e1df6d9d919ef0b76c7d1ca575afb070399f2e459d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
            "Successfully built wikipedia sgmllib3k\n",
            "Installing collected packages: sgmllib3k, requests, pydantic-core, ormsgpack, mypy-extensions, marshmallow, feedparser, wikipedia, typing-inspect, pydantic, arxiv, langgraph-sdk, groq, dataclasses-json, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain_groq, langgraph-prebuilt, langchain-classic, langgraph, langchain_community, langchain\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.11\n",
            "    Uninstalling langchain-text-splitters-0.3.11:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.11\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "gradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed arxiv-2.3.1 dataclasses-json-0.6.7 feedparser-6.0.12 groq-0.34.1 langchain-1.0.7 langchain-classic-1.0.0 langchain-core-1.0.5 langchain-text-splitters-1.0.0 langchain_community-0.4.1 langchain_groq-1.0.1 langgraph-1.0.3 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.4 langgraph-sdk-0.2.9 marshmallow-3.26.1 mypy-extensions-1.1.0 ormsgpack-1.12.0 pydantic-2.12.4 pydantic-core-2.41.5 requests-2.32.5 sgmllib3k-1.0.0 typing-inspect-0.9.0 wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph langsmith langchain langchain_groq langchain_community arxiv wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph.message import add_messages"
      ],
      "metadata": {
        "id": "P0CEHdCOFGGi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "groq_api_key = userdata.get('GROQ_API_KEY')\n",
        "langsmith = userdata.get('LANGSMITH_API_KEY')\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = langsmith\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph_chatbot_1\""
      ],
      "metadata": {
        "id": "dC5K19rwWv2w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "from langchain_community.utilities import ArxivAPIWrapper, WikipediaAPIWrapper\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# 2. Define input schemas for the tools\n",
        "class WikipediaInput(BaseModel):\n",
        "    query: str = Field(description=\"search query for Wikipedia\")\n",
        "\n",
        "class ArxivInput(BaseModel):\n",
        "    query: str = Field(description=\"search query for Arxiv\")\n",
        "\n",
        "# 3. Create tools using the @tool decorator.\n",
        "#    Instantiate API wrappers inside the function to avoid serialization issues\n",
        "@tool(\"wikipedia_search\", args_schema=WikipediaInput)\n",
        "def wikipedia_search(query: str) -> str:\n",
        "    \"\"\"Search Wikipedia for a given query and return the summary.\"\"\"\n",
        "    # Instantiate the wrapper each time the tool is called\n",
        "    _wikipedia_api_wrapper_instance = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=300)\n",
        "    return _wikipedia_api_wrapper_instance.run(query)\n",
        "\n",
        "@tool(\"arxiv_search\", args_schema=ArxivInput)\n",
        "def arxiv_search(query: str) -> str:\n",
        "    \"\"\"Search Arxiv for a given query and return the summary.\"\"\"\n",
        "    # Instantiate the wrapper each time the tool is called\n",
        "    _arxiv_api_wrapper_instance = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=300)\n",
        "    return _arxiv_api_wrapper_instance.run(query)\n",
        "\n",
        "# 4. Collect the tools\n",
        "tools = [wikipedia_search, arxiv_search]"
      ],
      "metadata": {
        "id": "FAC7BTcZFGPk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Wikipedia tool\n",
        "tools[0].invoke(\"who is J. K. Rowling\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "flOavcOhFGS9",
        "outputId": "28dd3ec3-61ff-4f97-c6a5-28f7fd7f5ac9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Page: Political views of J. K. Rowling\\nSummary: The British author J. K. Rowling, writer of Harry Potter and other Wizarding World works, has garnered attention for her support of the Labour Party under Gordon Brown and her criticism of the party under Jeremy Corbyn and Keir Starmer, as well as her '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Arxiv tool\n",
        "tools[1].invoke(\"What is Machane Learning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "aEJLDIDUFGV5",
        "outputId": "f818f727-2a15-42ad-89ac-dd21964999eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Published: 2017-05-15\\nTitle: Emotion in Reinforcement Learning Agents and Robots: A Survey\\nAuthors: Thomas M. Moerland, Joost Broekens, Catholijn M. Jonker\\nSummary: This article provides the first survey of computational models of emotion in reinforcement learning (RL) agents. The survey focuses on '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import BaseMessage\n",
        "# Langgraph Application\n",
        "class State(TypedDict):\n",
        "  # Messages have the type \"list\". The  \"add_messages\" function\n",
        "  # in the annotation defines how this state key should be updated\n",
        "  #(in this case, it appends messages to the list , rather than overwriting them)\n",
        "    messages: Annotated[list[BaseMessage], add_messages]"
      ],
      "metadata": {
        "id": "0cW0okJYFGbp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#class State(TypedDict):\n",
        "    # messages is now correctly updated using the imported add_messages\n",
        "   # messages: Annotated[list, add_messages]"
      ],
      "metadata": {
        "id": "Ww0oYepSl9Ic"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END"
      ],
      "metadata": {
        "id": "eARj01fKFGel"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder = StateGraph(State)"
      ],
      "metadata": {
        "id": "E0ugjxNgFGhX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "id": "L7yS_AYWFGkt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"llama-3.1-8b-instant\")"
      ],
      "metadata": {
        "id": "KoUE6Q7yFGoL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llam_with_tools = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "U3Ofrhh1YgOR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(state:State):\n",
        "  return {\"messages\":[llam_with_tools.invoke(state['messages'])]}"
      ],
      "metadata": {
        "id": "r6ciWgzdWidF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import ToolNode , tools_condition\n",
        "\n",
        "tool_node = ToolNode(tools=tools)\n",
        "\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "# --- Edges ---\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "\n",
        "# Use the prebuilt tools_condition to check if the LLM requested a tool\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    tools_condition,\n",
        "    {\"tools\": \"tools\", END: END} # Corrected: Map the actual END constant\n",
        ")\n",
        "\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "# No need for the tool -> END edge if tools_condition handles all termination"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTXETJWCWiaw",
        "outputId": "7fc1aabc-3414-4837-cc3b-0b0c02c32469"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x78a53ceaa090>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "memory_saver = MemorySaver()\n",
        "graph = graph_builder.compile(\n",
        "    checkpointer=memory_saver\n",
        ")"
      ],
      "metadata": {
        "id": "NgDHVU-mWiYm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "try:\n",
        "  display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "Fa4pfy2aWiW9",
        "outputId": "b20adcbf-6953-436b-e3ef-0b1b28305d90"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "user_input = \"Hi there! What's in your mind?\"\n",
        "initial_input = {\"messages\": [(\"user\", user_input)]}\n",
        "\n",
        "# Generate a unique thread ID for a clean run\n",
        "unique_thread_id = str(uuid.uuid4())\n",
        "\n",
        "# Use invoke() to run to completion, avoiding the buggy stream logic\n",
        "final_state = graph.invoke(\n",
        "    initial_input,\n",
        "    config={\"configurable\": {\"thread_id\": unique_thread_id}}\n",
        ")\n",
        "\n",
        "print(\"\\n--- Output History (via Invoke) ---\")\n",
        "\n",
        "# Iterate through the full list of messages in the final state\n",
        "for message in final_state[\"messages\"]:\n",
        "    try:\n",
        "        if hasattr(message, 'pretty_print'):\n",
        "            message.pretty_print()\n",
        "        else:\n",
        "            # Handle the initial tuple message\n",
        "            print(f\"Human Message: {message[1]}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error printing message: {e}\")"
      ],
      "metadata": {
        "id": "UaW7-7jwWiQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43cf65c2-0d53-4cca-f459-f536a48c10d8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Output History (via Invoke) ---\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hi there! What's in your mind?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I'm just a language model, I don't have personal thoughts or feelings like humans do, but I'm here to help with any questions or tasks you have. How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  user_input=input(\"User: \")\n",
        "  if user_input.lower() in (\"quit\",\"q\"):\n",
        "    print(\"Good Bye\")\n",
        "    break\n",
        "  for event in graph.stream(\n",
        "      {'messages':(\"user\", user_input)},\n",
        "      config={\"configurable\": {\"thread_id\": unique_thread_id}} # Added config here\n",
        "      ):\n",
        "    print(event.values())\n",
        "    for value in event.values():\n",
        "      print(value['messages'])\n",
        "      # The value['messages'] will now contain a list of messages. We need to access the last one to get the latest AI response.\n",
        "      # Also, ensure we are printing the content of the message object, not the message object itself.\n",
        "      latest_message = value['messages'][-1] if isinstance(value['messages'], list) else value['messages']\n",
        "      if hasattr(latest_message, 'content'):\n",
        "          print('Assistant:', latest_message.content)\n",
        "      else:\n",
        "          print('Assistant:', latest_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF3ovBawe2e_",
        "outputId": "8e939462-2614-4263-df03-83f72137635c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: hi\n",
            "dict_values([{'messages': [AIMessage(content=\"It seems like we're just starting a conversation. Is there something I can help you with, or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 360, 'total_tokens': 387, 'completion_time': 0.042979111, 'prompt_time': 0.023832332, 'queue_time': 0.035657064, 'total_time': 0.066811443}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_d834565e05', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--a9d0df9e-dc6c-41af-a811-b41027baf501-0', usage_metadata={'input_tokens': 360, 'output_tokens': 27, 'total_tokens': 387})]}])\n",
            "[AIMessage(content=\"It seems like we're just starting a conversation. Is there something I can help you with, or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 360, 'total_tokens': 387, 'completion_time': 0.042979111, 'prompt_time': 0.023832332, 'queue_time': 0.035657064, 'total_time': 0.066811443}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_d834565e05', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--a9d0df9e-dc6c-41af-a811-b41027baf501-0', usage_metadata={'input_tokens': 360, 'output_tokens': 27, 'total_tokens': 387})]\n",
            "Assistant: It seems like we're just starting a conversation. Is there something I can help you with, or would you like to chat?\n",
            "User: can you tell me about deep learning?\n",
            "dict_values([{'messages': [AIMessage(content=\"Deep learning is a subset of machine learning that involves the use of artificial neural networks with multiple layers to analyze and interpret data. These networks are designed to mimic the structure and function of the human brain, with each layer processing and transforming the input data in a way that allows the network to learn and improve its performance on a given task.\\n\\nDeep learning has been successful in a wide range of applications, including:\\n\\n- Image and speech recognition\\n- Natural language processing\\n- Game playing\\n- Time-series forecasting\\n- Recommendation systems\\n\\nSome common types of deep learning models include:\\n\\n- Convolutional neural networks (CNNs)\\n- Recurrent neural networks (RNNs)\\n- Long short-term memory (LSTM) networks\\n- Autoencoders\\n- Generative adversarial networks (GANs)\\n\\nHowever, deep learning also faces challenges such as:\\n\\n- The need for large amounts of training data\\n- The danger of overfitting\\n- The complexity of interpreting the results of deep learning models\\n\\nTo learn more about deep learning, I can provide you with some information about it, but I don't have an API to use to search for it.\\n\\n\", additional_kwargs={'tool_calls': [{'id': 'zn0dt2jn3', 'function': {'arguments': '{\"query\":\"deep learning\"}', 'name': 'arxiv_search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 248, 'prompt_tokens': 404, 'total_tokens': 652, 'completion_time': 0.349151293, 'prompt_time': 0.024228784, 'queue_time': 0.075837422, 'total_time': 0.373380077}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4dea31877a', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--fc4400bf-3e26-415c-85e7-74fdef9a9685-0', tool_calls=[{'name': 'arxiv_search', 'args': {'query': 'deep learning'}, 'id': 'zn0dt2jn3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 404, 'output_tokens': 248, 'total_tokens': 652})]}])\n",
            "[AIMessage(content=\"Deep learning is a subset of machine learning that involves the use of artificial neural networks with multiple layers to analyze and interpret data. These networks are designed to mimic the structure and function of the human brain, with each layer processing and transforming the input data in a way that allows the network to learn and improve its performance on a given task.\\n\\nDeep learning has been successful in a wide range of applications, including:\\n\\n- Image and speech recognition\\n- Natural language processing\\n- Game playing\\n- Time-series forecasting\\n- Recommendation systems\\n\\nSome common types of deep learning models include:\\n\\n- Convolutional neural networks (CNNs)\\n- Recurrent neural networks (RNNs)\\n- Long short-term memory (LSTM) networks\\n- Autoencoders\\n- Generative adversarial networks (GANs)\\n\\nHowever, deep learning also faces challenges such as:\\n\\n- The need for large amounts of training data\\n- The danger of overfitting\\n- The complexity of interpreting the results of deep learning models\\n\\nTo learn more about deep learning, I can provide you with some information about it, but I don't have an API to use to search for it.\\n\\n\", additional_kwargs={'tool_calls': [{'id': 'zn0dt2jn3', 'function': {'arguments': '{\"query\":\"deep learning\"}', 'name': 'arxiv_search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 248, 'prompt_tokens': 404, 'total_tokens': 652, 'completion_time': 0.349151293, 'prompt_time': 0.024228784, 'queue_time': 0.075837422, 'total_time': 0.373380077}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4dea31877a', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--fc4400bf-3e26-415c-85e7-74fdef9a9685-0', tool_calls=[{'name': 'arxiv_search', 'args': {'query': 'deep learning'}, 'id': 'zn0dt2jn3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 404, 'output_tokens': 248, 'total_tokens': 652})]\n",
            "Assistant: Deep learning is a subset of machine learning that involves the use of artificial neural networks with multiple layers to analyze and interpret data. These networks are designed to mimic the structure and function of the human brain, with each layer processing and transforming the input data in a way that allows the network to learn and improve its performance on a given task.\n",
            "\n",
            "Deep learning has been successful in a wide range of applications, including:\n",
            "\n",
            "- Image and speech recognition\n",
            "- Natural language processing\n",
            "- Game playing\n",
            "- Time-series forecasting\n",
            "- Recommendation systems\n",
            "\n",
            "Some common types of deep learning models include:\n",
            "\n",
            "- Convolutional neural networks (CNNs)\n",
            "- Recurrent neural networks (RNNs)\n",
            "- Long short-term memory (LSTM) networks\n",
            "- Autoencoders\n",
            "- Generative adversarial networks (GANs)\n",
            "\n",
            "However, deep learning also faces challenges such as:\n",
            "\n",
            "- The need for large amounts of training data\n",
            "- The danger of overfitting\n",
            "- The complexity of interpreting the results of deep learning models\n",
            "\n",
            "To learn more about deep learning, I can provide you with some information about it, but I don't have an API to use to search for it.\n",
            "\n",
            "\n",
            "dict_values([{'messages': [ToolMessage(content='Published: 2023-06-24\\nTitle: Learn to Accumulate Evidence from All Training Samples: Theory and Practice\\nAuthors: Deep Pandey, Qi Yu\\nSummary: Evidential deep learning, built upon belief theory and subjective logic, offers a principled and computationally efficient way to turn a deterministic neural ', name='arxiv_search', id='d89c815d-435d-4894-b207-54a0b50c9228', tool_call_id='zn0dt2jn3')]}])\n",
            "[ToolMessage(content='Published: 2023-06-24\\nTitle: Learn to Accumulate Evidence from All Training Samples: Theory and Practice\\nAuthors: Deep Pandey, Qi Yu\\nSummary: Evidential deep learning, built upon belief theory and subjective logic, offers a principled and computationally efficient way to turn a deterministic neural ', name='arxiv_search', id='d89c815d-435d-4894-b207-54a0b50c9228', tool_call_id='zn0dt2jn3')]\n",
            "Assistant: Published: 2023-06-24\n",
            "Title: Learn to Accumulate Evidence from All Training Samples: Theory and Practice\n",
            "Authors: Deep Pandey, Qi Yu\n",
            "Summary: Evidential deep learning, built upon belief theory and subjective logic, offers a principled and computationally efficient way to turn a deterministic neural \n",
            "dict_values([{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '3tcbnzcca', 'function': {'arguments': '{\"query\":\"deep learning\"}', 'name': 'wikipedia_search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 497, 'total_tokens': 513, 'completion_time': 0.015319634, 'prompt_time': 0.033782255, 'queue_time': 0.036882729, 'total_time': 0.049101889}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_d834565e05', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--3c06f021-1ab6-43dd-b442-6d4355d54963-0', tool_calls=[{'name': 'wikipedia_search', 'args': {'query': 'deep learning'}, 'id': '3tcbnzcca', 'type': 'tool_call'}], usage_metadata={'input_tokens': 497, 'output_tokens': 16, 'total_tokens': 513})]}])\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '3tcbnzcca', 'function': {'arguments': '{\"query\":\"deep learning\"}', 'name': 'wikipedia_search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 497, 'total_tokens': 513, 'completion_time': 0.015319634, 'prompt_time': 0.033782255, 'queue_time': 0.036882729, 'total_time': 0.049101889}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_d834565e05', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--3c06f021-1ab6-43dd-b442-6d4355d54963-0', tool_calls=[{'name': 'wikipedia_search', 'args': {'query': 'deep learning'}, 'id': '3tcbnzcca', 'type': 'tool_call'}], usage_metadata={'input_tokens': 497, 'output_tokens': 16, 'total_tokens': 513})]\n",
            "Assistant: \n",
            "dict_values([{'messages': [ToolMessage(content='Page: Deep learning\\nSummary: In machine learning, deep learning focuses on utilizing multilayered neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and revolves around stacking artificial neurons', name='wikipedia_search', id='d7fb6423-53cb-4402-8479-64256bfba8ce', tool_call_id='3tcbnzcca')]}])\n",
            "[ToolMessage(content='Page: Deep learning\\nSummary: In machine learning, deep learning focuses on utilizing multilayered neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and revolves around stacking artificial neurons', name='wikipedia_search', id='d7fb6423-53cb-4402-8479-64256bfba8ce', tool_call_id='3tcbnzcca')]\n",
            "Assistant: Page: Deep learning\n",
            "Summary: In machine learning, deep learning focuses on utilizing multilayered neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and revolves around stacking artificial neurons\n",
            "dict_values([{'messages': [AIMessage(content=\"It seems like you're looking for more information on deep learning. I provided summaries from Wikipedia and Arxiv. If you need more information or clarification on any topic, feel free to ask.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 571, 'total_tokens': 610, 'completion_time': 0.078454077, 'prompt_time': 0.039920413, 'queue_time': 0.035311745, 'total_time': 0.11837449}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_d834565e05', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--bf6d05c1-cb6c-4ca8-9f3d-b89619bfc764-0', usage_metadata={'input_tokens': 571, 'output_tokens': 39, 'total_tokens': 610})]}])\n",
            "[AIMessage(content=\"It seems like you're looking for more information on deep learning. I provided summaries from Wikipedia and Arxiv. If you need more information or clarification on any topic, feel free to ask.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 571, 'total_tokens': 610, 'completion_time': 0.078454077, 'prompt_time': 0.039920413, 'queue_time': 0.035311745, 'total_time': 0.11837449}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_d834565e05', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--bf6d05c1-cb6c-4ca8-9f3d-b89619bfc764-0', usage_metadata={'input_tokens': 571, 'output_tokens': 39, 'total_tokens': 610})]\n",
            "Assistant: It seems like you're looking for more information on deep learning. I provided summaries from Wikipedia and Arxiv. If you need more information or clarification on any topic, feel free to ask.\n",
            "User: q\n",
            "Good Bye\n"
          ]
        }
      ]
    }
  ]
}